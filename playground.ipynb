{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground Notebook\n",
    "## To try, validate and debug the code into the dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Home directory\n",
    "home_dir = os.path.expanduser(r'~/Documents/ZHAW/MAIN/04_Big_Data/30_Project/')\n",
    "# Stock market data directory\n",
    "stock_dir = r'spark-stock-market-streaming/collected_data/'\n",
    "# Tweet data directory\n",
    "tweet_dir = r'???'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Dataframe from json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildDF(base_dir, data_dir, json_col):\n",
    "    '''Construct a big dataframe by aggregating the individual json files\n",
    "    located at the proper data directory\n",
    "    Args:\n",
    "        base_dir(str), the home or base directory\n",
    "        data_dir(str), the directory containing the data\n",
    "        json_col(str), which column to normalize from the json file\n",
    "    return:\n",
    "        df(dataframe), full dataframe iaw json structure'''\n",
    "    folder = os.path.join(base_dir + data_dir)\n",
    "    files = os.listdir(folder)\n",
    "    count_files = 0\n",
    "    for file in files:\n",
    "        file_path = os.path.join(folder + file)\n",
    "        with open(file_path) as data_file:\n",
    "            data = json.load(data_file)\n",
    "            if count_files == 0:\n",
    "                df = json_normalize(data, json_col)\n",
    "                print('---- Base Dataframe ----')\n",
    "                print('Lenght of base dataframe is: ', len(df))\n",
    "                print(file_path)\n",
    "                print(df.head())\n",
    "                count_files += 1\n",
    "            else:\n",
    "                df_temp = json_normalize(data, json_col)\n",
    "                df = df.append(df_temp, ignore_index=True)\n",
    "                count_files += 1\n",
    "    print('------------------------')\n",
    "    print('Total files read: ' + str(count_files))\n",
    "    print('---- %d Dataframes appended ----' %count_files)\n",
    "    print('Total lenght of dataframe is: ', len(df))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Base Dataframe ----\n",
      "Lenght of base dataframe is:  10\n",
      "/home/hase/Documents/ZHAW/MAIN/04_Big_Data/30_Project/spark-stock-market-streaming/collected_data/20180606-220010.json\n",
      "  1. symbol  2. price 3. volume         4. timestamp\n",
      "0      TSLA  319.4700  18529555  2018-06-06 16:00:00\n",
      "1      AAPL  194.0000  19893045  2018-06-06 16:00:00\n",
      "2      MSFT  102.4450  19485170  2018-06-06 16:00:00\n",
      "3       MCD  162.3250   2723457  2018-06-06 16:00:00\n",
      "4       NKE   74.7350   4346701  2018-06-06 16:00:00\n",
      "------------------------\n",
      "Total files read: 530\n",
      "---- 530 Dataframes appended ----\n",
      "Total lenght of dataframe is:  5300\n"
     ]
    }
   ],
   "source": [
    "dfs = buildDF(home_dir, stock_dir, 'Stock Quotes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transDF(df, stamp, header):\n",
    "    '''Pre-processing of the data by doing some transformations\n",
    "    and aggregations to the dataframe created previously\n",
    "    Args:\n",
    "        df(dataframe): input dataframe\n",
    "        stamp(str): name column to parse for datetime\n",
    "        header(dict): a dictionary with {'original col name':'new col name'}\n",
    "    return:\n",
    "        df(dataframe): transformed dataframe'''\n",
    "    print('---- Input Dataframe ----')\n",
    "    print(df.head())\n",
    "    # Parse date and time\n",
    "    print('------------------------')\n",
    "    print('Parsing datetimes...')\n",
    "    df['stamp'] = pd.to_datetime(df[stamp])\n",
    "    df['year'] = df['stamp'].dt.year\n",
    "    df['month'] = df['stamp'].dt.month\n",
    "    df['day'] = df['stamp'].dt.day\n",
    "    df['hour'] = df['stamp'].dt.hour\n",
    "    df['minute'] = df['stamp'].dt.minute\n",
    "    df['second'] = df['stamp'].dt.second\n",
    "    # Drop unneeded columns\n",
    "    print('Dropping columns...')\n",
    "    df.drop([stamp], axis=1, inplace=True)\n",
    "    # Set dataframe index\n",
    "    df.set_index('stamp', inplace=True)\n",
    "    print('Index set to: ', stamp)\n",
    "    # Rename columns\n",
    "    print('Renaming columns...')\n",
    "    df.rename(columns=header, inplace=True)\n",
    "    print('Drop duplicates...')\n",
    "    original_len = len(df)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    drop_len = len(df)\n",
    "    print('Dataframe reduced from %d to %d rows' %(original_len, drop_len))\n",
    "    print('---- Modified Dataframe ----')\n",
    "    print(df.head())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Input Dataframe ----\n",
      "  1. symbol  2. price 3. volume         4. timestamp\n",
      "0      TSLA  319.4700  18529555  2018-06-06 16:00:00\n",
      "1      AAPL  194.0000  19893045  2018-06-06 16:00:00\n",
      "2      MSFT  102.4450  19485170  2018-06-06 16:00:00\n",
      "3       MCD  162.3250   2723457  2018-06-06 16:00:00\n",
      "4       NKE   74.7350   4346701  2018-06-06 16:00:00\n",
      "------------------------\n",
      "Parsing datetimes...\n",
      "Dropping columns...\n",
      "Index set to:  4. timestamp\n",
      "Renaming columns...\n",
      "Drop duplicates...\n",
      "Dataframe reduced from 5300 to 3695 rows\n",
      "---- Modified Dataframe ----\n",
      "                      sym         $       vol  year  month  day  hour  minute  \\\n",
      "stamp                                                                           \n",
      "2018-06-06 16:00:00  TSLA  319.4700  18529555  2018      6    6    16       0   \n",
      "2018-06-06 16:00:00  AAPL  194.0000  19893045  2018      6    6    16       0   \n",
      "2018-06-06 16:00:00  MSFT  102.4450  19485170  2018      6    6    16       0   \n",
      "2018-06-06 16:00:00   MCD  162.3250   2723457  2018      6    6    16       0   \n",
      "2018-06-06 16:00:00   NKE   74.7350   4346701  2018      6    6    16       0   \n",
      "\n",
      "                     second  \n",
      "stamp                        \n",
      "2018-06-06 16:00:00       0  \n",
      "2018-06-06 16:00:00       0  \n",
      "2018-06-06 16:00:00       0  \n",
      "2018-06-06 16:00:00       0  \n",
      "2018-06-06 16:00:00       0  \n"
     ]
    }
   ],
   "source": [
    "dfss = transDF(dfs, '4. timestamp',\n",
    "               {'1. symbol':'sym',\n",
    "                '2. price':'$', \n",
    "                '3. volume':'vol'}\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dfss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
